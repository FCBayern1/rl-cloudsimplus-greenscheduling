# ===================================================================
# config.yml - Default Configuration for DRL Load Balancing/Scaling
# ===================================================================

common:
  # --- Simulation Identification ---
  simulation_name: "DefaultSimRun" # Used in logging and result file names

  # --- Simulation Control & Timing ---
  simulation_timestep: 1.0 # Duration of each RL agent step (seconds)
  min_time_between_events: 0.1 # CloudSim internal minimum time granularity (s)
  max_episode_length: 500 # Max steps per episode before truncation (1 hour to cover green energy data points)

  # --- Host Configuration ---
  hosts_count: 32 # Number of physical hosts/servers
  host_pes: 16 # Processing Elements (cores) per host
  host_pe_mips: 50000 # MIPS capacity per PE (core)
  host_ram: 65536  # Host RAM in MB (640 GB)
  host_bw: 50000  # Host Bandwidth in Mbps (100 Gbps)
  host_storage: 100000  # Host Storage in MB (100 GB)

  # --- VM Configuration (Base 'S' & Multipliers) ---
  small_vm_pes: 2 # PEs for base 'S' VM (like m5a.large)
  small_vm_ram: 8192 # RAM (MB) for 'S' VM (8 GB)
  small_vm_bw: 10000 # Bandwidth (Mbps) for 'S' VM (1 Gbps)
  small_vm_storage: 10000 # Storage (MB) for 'S' VM (4 GB)
  medium_vm_multiplier: 2 # 'M' VM PEs/RAM = multiplier * 'S' (e.g., 4 PEs, 16GB RAM)
  large_vm_multiplier: 4 # 'L' VM PEs/RAM = multiplier * 'S' (e.g., 8 PEs, 32GB RAM)

  # --- Initial VM Fleet ---
  initial_s_vm_count: 20  # Start with 0 Small VMs
  initial_m_vm_count: 10 # Start with 0 Medium VM
  initial_l_vm_count: 5 # Start with 0 Large VMs

  # --- VM Lifecycle Delays ---
  vm_startup_delay: 0.0 # Time (sec) for VM to boot (reduced for faster testing)
  vm_shutdown_delay: 0.0 # Time (sec) before idle VM is destroyed by broker (agent action is immediate)

  # --- Workload Configuration ---
  workload_mode: "SWF" # Options: "SWF", "CSV"
  cloudlet_trace_file: "traces/LLNL-Atlas-2006-2.1-cln-test.swf" # Default trace file path (relative to resources)
  max_cloudlets_to_create_from_workload_file: 2147483647 # Limit lines read for faster testing (Set to MAX_INT for full file)
  workload_reader_mips: 50000 # MIPS ref for SWF length calc (match host_pe_mips)
  split_large_cloudlets: true # Split cloudlets requesting more PEs than max_cloudlet_pes?
  max_cloudlet_pes: 8 # Max PEs a single (split) cloudlet can request (e.g., = large VM PEs)

  # --- Costing Configuration ---
  small_vm_hourly_cost: 0.086 # Approx AWS m5a.large hourly cost ($)
  paying_for_the_full_hour: false # Billing model (false = per-second approx)

  # --- Reward Weights ---
  # Note: Tune these weights heavily based on experimental results!
  reward_wait_time_coef: 0.75 # Penalty for FINISHED CLOUDLETS WAIT TIME (Avg per step)
  reward_throughput_coef: 0.85 # Reward for THROUGHPUT (Avg Cloudlets Finished per step)
  reward_unutilization_coef: 0.25 # Penalty for avg VM CPU UNUTILIZATION (1.0 - utilization)
  reward_cost_coef: 0.35 # Penalty for INFRASTRUCTURE COST (Allocated Cores / Total Cores Ratio)
  reward_queue_penalty_coef: 0.55 # Penalty for number of WAITING cloudlets (normalized)
  reward_invalid_action_coef: 1.0 # Flat penalty for attempting an invalid action

  # --- Green Energy Configuration ---
  # Enable wind turbine power integration for green datacenter scheduling
  green_energy:
    enabled: true                                     # Enable/disable green energy provider
    turbine_id: 57                                      # Wind turbine ID to load from dataset
    prediction:
      enabled: false                                    # Enable/disable power prediction
      model_path: "../SWF_Prediction/saved_models/best_model.pth"  # Path to trained prediction model
      cache_duration_seconds: 600                       # Cache prediction results for 10 minutes
      horizon: 8                                        # Predict 8 timesteps ahead (80 minutes)

  # --- Future Energy Forecast (God's Eye Mode) ---
  # Provide future green energy trend features to RL agent using ground truth CSV data
  future_energy_forecast:
    # Short-term features: Next 30 minutes (3 CSV rows √ó 10 min/row)
    # - dc_future_short_mean: Average power level [0, 1]
    # - dc_future_short_trend: Trend direction [-1, 1]
    short_term_rows: 3                                  # Number of CSV rows for short-term (30 min)

    # Long-term features: Next 24 hours (144 CSV rows √ó 10 min/row)
    # - dc_future_long_mean: Average power level [0, 1]
    # - dc_future_long_peak_timing: When peak occurs [0, 1] (0=now, 1=24h later)
    long_term_rows: 144                                 # Number of CSV rows for long-term (24 hours)

  # # --- Observation Normalization ---
  # max_queue_norm: 100.0 # Expected max queue length for normalizing observation
  # max_pes_norm: 8.0 # Expected max PEs for normalizing next_cloudlet_pes obs (e.g., largest VM size)
  # # tree_array_max_len: 5000          # Optional: Manually set Tree Array padding size (if calculated value is unstable/undesired)

  # --- Technical Flags ---
  clear_created_lists: true # Optimization: Clear internal CloudSim broker lists

  # --- Python/RL Parameters ---
  env_id: "LoadBalancingScaling-v0" # Gym environment ID to use
  mode: "train" # Default execution mode: "train", "test"
  algorithm: "PPO" # RL algorithm ("MaskablePPO", "PPO", "A2C", etc.)
  policy: "MultiInputPolicy" # Network policy for Dict observation space
  timesteps: 1000 # Total training timesteps
  learning_rate: 0.0003 # Optimizer learning rate
  n_steps: 2048 # (PPO/A2C) Steps per policy update
  batch_size: 64 # (PPO/Others) Minibatch size for training
  n_epochs: 10 # (PPO) Optimisation epochs per update
  gamma: 0.99 # Discount factor for future rewards
  gae_lambda: 0.95 # (PPO/A2C) Factor for Generalized Advantage Estimation
  clip_range: 0.2 # (PPO) Clipping parameter
  ent_coef: 0.01 # Entropy coefficient (exploration bonus)
  vf_coef: 0.5 # Value function coefficient in loss
  max_grad_norm: 0.5 # Max gradient norm for clipping
  # policy_kwargs: # Optional: e.g., net_arch: [128, 128]
  verbose: 0 # SB3 Verbosity level (0=minimal, 1=info, 2=debug)
  log_interval: 1 # Log stats every N episodes
  seed: 4567 # Default random seed for Python/Torch/Numpy/Env
  save_experiment: true # Save logs, models, etc.
  base_log_dir: "logs" # Root directory for all logs
  experiment_type_dir: "DefaultType" # Subdirectory for this type of experiment (e.g., "SWF_Tests", "CSV_Tests")
  train_model_dir: "" # REQUIRED FOR TEST/TRANSFER: Path to trained model log dir (relative to base_log_dir)
  save_replay_buffer: false # Save replay buffer with best model (only for off-policy algos)
  device: "auto" # Device for PyTorch ("auto", "cpu", "cuda")

  # --- Early Stopping (Evaluation-Based) ---
  # Enable and configure EvalCallback-driven early stopping.
  # type: "no_improvement" stops after 'patience' eval rounds without improvement.
  # type: "reward_threshold" stops when the eval mean reward reaches the threshold.
  early_stop:
    enabled: false
    type: "no_improvement"            # Options: "no_improvement", "reward_threshold"
    eval_freq: 5000                    # Evaluate every N training steps
    n_eval_episodes: 5                 # Episodes per evaluation
    patience: 5                        # For no_improvement: max eval rounds without improvement
    min_evals: 5                       # For no_improvement: minimum eval rounds before checking
    # reward_threshold: 200.0            # For reward_threshold: stop when reached

# ===================================================================
# Experiment-Specific Overrides (Define different runs below)
# ===================================================================

experiment_1:
  simulation_name: "Exp1_CSVSimple_GreenEnergy" # Unique name for logging this specific run
  experiment_name: "Exp1_CSVSimple_GreenEnergy" # Name for the log sub-folder
  experiment_type_dir: "CSV_Train"
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/three_60max_8maxcores.csv"

  mode: "train"
  algorithm: "MaskablePPO"  # Use MaskablePPO to reduce invalid actions
  timesteps: 50000  # Longer training
  learning_rate: 0.0001  # Lower LR for stability

  max_episode_length: 5000

  n_steps: 1024  # Smaller for more frequent updates
  batch_size: 128
  n_epochs: 15
  gamma: 0.995
  gae_lambda: 0.98
  clip_range: 0.2
  ent_coef: 0.02  # Increase exploration

  # Green Energy Configuration - Testing wind turbine integration
  green_energy:
    enabled: true                                     
    turbine_id: 57                                    
    wind_data_file: "windProduction/processed_data/cleaned_data.csv"
    prediction:
      enabled: false                                  # Disable prediction for now
      model_path: "../SWF_Prediction/saved_models/best_model.pth"
      cache_duration_seconds: 600
      horizon: 8

  # Reward Weights - Added energy coefficient for green energy optimization
  reward_wait_time_coef: 0.1        # Wait time penalty
  reward_throughput_coef: 0.085     # Throughput reward
  reward_unutilization_coef: 0.05   # Utilization penalty
  reward_cost_coef: 0.05            # Cost penalty
  reward_queue_penalty_coef: 0.055  # Queue penalty
  reward_energy_coef: 0.2           # ‚úÖ Energy consumption penalty (new for green energy)
  reward_invalid_action_coef: 0.2   # Invalid action penalty

# ===================================================================
# Experiment 2: Large-Scale LLNL Workload with Optimized Parameters
# ===================================================================
experiment_2:
  simulation_name: "Exp2_LLNL_Large_Optimized"
  experiment_name: "exp2_llnl_large"
  experiment_type_dir: "LargeScale_Experiments"
  
  # Workload Configuration
  workload_mode: "SWF"
  cloudlet_trace_file: "traces/LLNL-Atlas-2006-2.1-cln.swf"
  max_cloudlets_to_create_from_workload_file: 500  # Start with 500 tasks (full dataset: 43810)
  workload_reader_mips: 50000
  split_large_cloudlets: true
  max_cloudlet_pes: 8
  
  # RL Algorithm Configuration (Optimized)
  mode: "train"
  algorithm: "MaskablePPO"  # Use MaskablePPO to reduce invalid actions
  timesteps: 50000  # Longer training
  learning_rate: 0.0001  # Lower LR for stability
  
  # PPO Hyperparameters
  n_steps: 512  # Smaller for more frequent updates
  batch_size: 128
  n_epochs: 15
  gamma: 0.995
  gae_lambda: 0.98
  clip_range: 0.2
  ent_coef: 0.02  # Increase exploration
  
  # Infrastructure Configuration (Optimized)
  hosts_count: 32
  host_pes: 16
  host_pe_mips: 50000
  host_ram: 65536
  
  # Reduce initial VMs to force RL to learn efficient scaling
  initial_s_vm_count: 10  # Reduced from 20
  initial_m_vm_count: 5   # Reduced from 10
  initial_l_vm_count: 2   # Reduced from 5
  
  # Reward Weights (Optimized)
  reward_wait_time_coef: 1.0        # Increase wait time penalty
  reward_throughput_coef: 0.85
  reward_unutilization_coef: 0.5    # Double utilization weight (from 0.25)
  reward_cost_coef: 0.5             # Increase cost weight (from 0.35)
  reward_queue_penalty_coef: 0.55
  reward_invalid_action_coef: 2.0   # Harshly penalize invalid actions (from 1.0)
  
  # Experiment Control
  max_episode_length: 500
  seed: 42  # Fixed seed for reproducibility
  save_experiment: true
  device: "auto"
  verbose: 1  # Show detailed training info
  log_interval: 1

# ===================================================================
# Experiment 3: Quick Test with CSV Workload
# ===================================================================
experiment_3:
  simulation_name: "Exp3_CSV_QuickTest_Fixed"
  experiment_name: "exp3_csv_quick"
  experiment_type_dir: "QuickTests"
  
  # Quick Test Configuration - Using CSV instead of SWF
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/three_60max_8maxcores.csv"  # CSV with reasonable arrival times
  
  mode: "train"
  algorithm: "MaskablePPO"
  learning_rate: 0.0005
  timesteps: 120000  # Increase for better learning
  
  # Use optimized parameters
  initial_s_vm_count: 20
  initial_m_vm_count: 10
  initial_l_vm_count: 4

  n_steps: 512  # Smaller for more frequent updates
  batch_size: 128
  n_epochs: 15
  gamma: 0.995
  gae_lambda: 0.98
  clip_range: 0.2
  ent_coef: 0.02  # Increase exploration
  
  reward_unutilization_coef: 0.5
  reward_cost_coef: 0.5
  reward_invalid_action_coef: 2.0


# ===================================================================
# Experiment 10: Real SPEC Servers - Authentic Power Profiles
# ===================================================================
# Uses exact server configurations from SPEC power_ssj2008 benchmark data
# Includes legacy inefficient servers and modern efficient AMD EPYC systems
# Realistic heterogeneous datacenter with wide efficiency range (12.5% to 57.6% idle power)
# ===================================================================

experiment_10_spec_real:
  # --- Identification ---
  simulation_name: "Exp10_SPEC_RealServers"
  experiment_name: "exp10_spec_real"
  experiment_type_dir: "SPEC_Authentic"

  # --- Workload ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/poisson_05_300.csv"

  # --- Training ---
  mode: "train"
  algorithm: "MaskablePPO"
  timesteps: 150000              # Extended training for complex server selection
  learning_rate: 0.0005

  # --- PPO Hyperparameters ---
  n_steps: 512
  batch_size: 128
  n_epochs: 15
  gamma: 0.995
  gae_lambda: 0.98
  ent_coef: 0.05

  # üåü SPEC POWER_SSJ2008 REAL SERVERS üåü
  # Enable heterogeneous datacenter with exact benchmark data
  enable_heterogeneous_hosts: true

  # Real server distribution (total: 28 hosts)
  # Using actual SPEC power_ssj2008 benchmark data from ASUSTeK and Acer:

  host_count_spec_acer_r520: 4        # Acer Altos R520 (Legacy)
                                       # - Intel Xeon E5450, 8 cores, 16GB RAM
                                       # - Idle: 155W, Peak: 269W (57.6% idle!)
                                       # - Very inefficient, legacy workloads only
                                       # - Realistic: old servers still in production

  host_count_spec_acer_ar360: 6       # Acer AR360 F2 (Medium Older)
                                       # - Intel Xeon E5-2660, 16 cores, 32GB RAM
                                       # - Idle: 69.4W, Peak: 315W (22.0% idle)
                                       # - Transition-era efficiency

  host_count_spec_asus_rs720_e9: 8    # ASUSTeK RS720-E9/RS8 (Modern Efficient)
                                       # - Intel Xeon Platinum 8180, 56 cores, 128GB RAM
                                       # - Idle: 48.2W, Peak: 385W (12.5% idle) ‚ö°
                                       # - HIGHLY EFFICIENT: Best idle power ratio
                                       # - Primary workhorse servers

  host_count_spec_asus_rs500a: 8      # ASUSTeK RS500A-E10-PS4 (Large AMD EPYC)
                                       # - AMD EPYC 7742, 64 cores, 256GB RAM
                                       # - Idle: 51.4W, Peak: 214W (24.0% idle)
                                       # - EXTREMELY POWER EFFICIENT: Lowest peak power
                                       # - 64 cores with only 214W peak!

  host_count_spec_asus_rs700a: 2      # ASUSTeK RS700A-E9-RS4V2 (Ultra Dual-Socket)
                                       # - AMD EPYC 7742 x2, 128 cores, 512GB RAM
                                       # - Idle: 106W, Peak: 430W (24.7% idle)
                                       # - Massive capacity for peak loads

  hosts_count: 28                      # Total (4+6+8+8+2 = 28 hosts)

  # --- VM Fleet (Optimized for SPEC server capacities) ---
  initial_s_vm_count: 30              # Small VMs for light tasks
  initial_m_vm_count: 15               # Medium VMs for balanced workloads
  initial_l_vm_count: 10               # Large VMs for heavy computation

  # --- Reward Weights (Green Optimization with Real Server Data) ---
  reward_wait_time_coef: 1.0          # Maintain performance
  reward_unutilization_coef: 1.0      # High utilization to minimize active servers
  reward_cost_coef: 0.5
  reward_queue_penalty_coef: 0.8
  reward_invalid_action_coef: 2.0
  reward_energy_coef: 1.5              # - Strong energy optimization
                                       # - Agent should learn:
                                       # - Avoid Acer R520 (57.6% idle - terrible!)
                                       # - Prefer ASUS RS720 (12.5% idle - excellent!)
                                       # - Use ASUS RS500A for efficiency (214W peak!)
                                       # - Reserve RS700A for true peak demands

  # --- Episode Configuration ---
  max_episode_length: 2000              # Increased to allow natural episode completion

  # --- Other Settings ---
  seed: 1010
  save_experiment: true
  verbose: 1
  device: "cuda"  # Force CPU (RTX 5080 not supported yet)


# ===================================================================
# DEBUG: Single Episode Test
# ===================================================================
experiment_10_spec_real_debug:
  # --- Identification ---
  simulation_name: "Exp10_SPEC_DEBUG"
  experiment_name: "exp10_spec_real_debug"
  experiment_type_dir: "DEBUG"

  # --- Workload ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/three_60max_8maxcores.csv"

  # --- Training: ONLY 1 EPISODE ---
  mode: "train"
  algorithm: "MaskablePPO"
  timesteps: 400              # Just enough for 1 episode
  learning_rate: 0.0003

  # --- PPO Hyperparameters ---
  n_steps: 512
  batch_size: 128
  n_epochs: 15
  gamma: 0.995
  gae_lambda: 0.98
  ent_coef: 0.05

  # SPEC Servers
  enable_heterogeneous_hosts: true
  host_count_spec_acer_r520: 4
  host_count_spec_acer_ar360: 6
  host_count_spec_asus_rs720_e9: 8
  host_count_spec_asus_rs500a: 8
  host_count_spec_asus_rs700a: 2
  hosts_count: 28

  # VM Fleet
  initial_s_vm_count: 12
  initial_m_vm_count: 8
  initial_l_vm_count: 6

  # Reward Weights
  reward_wait_time_coef: 1.0
  reward_unutilization_coef: 1.0
  reward_cost_coef: 0.5
  reward_queue_penalty_coef: 0.8
  reward_invalid_action_coef: 2.0
  reward_energy_coef: 2.5

  # Episode Configuration
  max_episode_length: 600  # Increased to allow natural episode completion

  # Other Settings
  seed: 1010
  save_experiment: true
  verbose: 2               # VERBOSE logging!
  device: "cuda"

# ===================================================================
# Experiment 3 - Debug Version 2: Reward Rebalancing (RECOMMENDED)
# ===================================================================
# Goal: Fix reward component imbalance to encourage fast completion
# Key changes:
# 1. Increase wait time penalty (0.75 ‚Üí 2.0)
# 2. Increase throughput reward (0.85 ‚Üí 1.5)
# 3. Decrease unutilization penalty (0.5 ‚Üí 0.3) - avoid over-optimization
# 4. Increase queue penalty (0.55 ‚Üí 1.0) - reduce waiting
# 5. Shorten episode length (1200 ‚Üí 400) - force faster completion
# ===================================================================

experiment_3_debug_v2:
  simulation_name: "Exp3_Debug_RewardBalance"
  experiment_name: "exp3_debug_reward"
  experiment_type_dir: "QuickTests"

  # --- Workload (Same as Exp3) ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/three_60max_8maxcores.csv"

  # --- Training ---
  mode: "train"
  algorithm: "MaskablePPO"
  timesteps: 320000          # 120000 ‚Üí 150000 (more training)
  learning_rate: 0.0005      # Keep same as Exp3

  # --- PPO Hyperparameters (Same as Exp3) ---
  n_steps: 1024
  batch_size: 128
  n_epochs: 15
  gamma: 0.995
  gae_lambda: 0.98
  clip_range: 0.2
  ent_coef: 0.02             # Keep exploration same for now

  # --- VM Fleet (Same as Exp3) ---
  initial_s_vm_count: 20
  initial_m_vm_count: 10
  initial_l_vm_count: 4

  # --- Reward Weights (KEY CHANGES!) ---
  reward_wait_time_coef: 0.2
  reward_throughput_coef: 0.15
  reward_unutilization_coef: 0.03
  reward_cost_coef: 0.03 
  reward_queue_penalty_coef: 0.1
  reward_invalid_action_coef: 0.2

  # --- Episode Configuration ---
  max_episode_length: 800    # 1200 ‚Üí 400 (force faster completion)

  # --- Other Settings ---
  seed: 43                   # Different seed from Exp3
  save_experiment: true
  verbose: 1
  device: "auto"
# ===================================================================
# Experiment 4: MaskablePPO + LSTM policy
# ===================================================================
experiment_4_maskable_lstm:
  simulation_name: "Exp4_RecurrentPPO_LSTM"
  experiment_name: "exp4_maskable_lstm"
  experiment_type_dir: "RecurrentPolicies"

  workload_mode: "CSV"
  cloudlet_trace_file: "traces/three_60max_8maxcores.csv"

  mode: "train"
  algorithm: "RecurrentPPO"
  policy: "MultiInputLstmPolicy"   # Dict observation ‚Üí use MultiInput variant

  timesteps: 120000                # Need multiple updates for LSTM credit assignment
  learning_rate: 0.0002
  n_steps: 1024                    # Prefer multiples of episode length for RNNs
  batch_size: 256                  # Must divide n_steps * n_envs; here n_envs=1
  n_epochs: 10
  gamma: 0.995
  gae_lambda: 0.95
  clip_range: 0.15
  ent_coef: 0.01
  vf_coef: 0.3
  max_grad_norm: 0.5

  reward_wait_time_coef: 0.2
  reward_throughput_coef: 0.15
  reward_unutilization_coef: 0.03
  reward_cost_coef: 0.03 
  reward_queue_penalty_coef: 0.1
  reward_invalid_action_coef: 0.2


  policy_kwargs:
    lstm_hidden_size: 256
    n_lstm_layers: 1
    shared_lstm: true              # Actor & critic share the LSTM core
    enable_critic_lstm: false      # MUST be false when shared_lstm=true
    # For shared LSTM: input ‚Üí LSTM ‚Üí split to pi/vf MLP heads
    net_arch:
      pi: [128]                    # MLP head after shared LSTM for actor
      vf: [128]                    # MLP head after shared LSTM for critic
  
  seed: 42
  save_experiment: true
  max_episode_length: 800  # Shorter for CSV workload (164 tasks)
  
experiment_11_long:
  # --- Identification ---
  simulation_name: "Exp11_LongEpisode_3600s"
  experiment_name: "exp11_3600s"
  experiment_type_dir: "LongEpisode"

  # --- Workload Configuration ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/poisson_04_3600.csv"  # 1426 tasks, 3600s
  workload_reader_mips: 50000
  split_large_cloudlets: true
  max_cloudlet_pes: 8

  # --- Infrastructure Configuration ---
  # Host setup: 16 hosts √ó 16 cores = 256 total cores
  # Provides 3x capacity vs average demand (58 cores), 3x vs peak (87 cores)
  hosts_count: 32
  host_pes: 16
  host_pe_mips: 50000
  host_ram: 65536      # 64 GB per host
  host_bw: 50000       # 50 Gbps
  host_storage: 100000 # 100 GB

  # --- VM Configuration ---
  small_vm_pes: 2
  small_vm_ram: 8192
  small_vm_bw: 1000
  small_vm_storage: 4000
  medium_vm_multiplier: 2   # Medium: 4 PEs
  large_vm_multiplier: 4    # Large: 8 PEs

  # --- Initial VM Fleet ---
  # Total: 20√ó2 + 10√ó4 + 5√ó8 = 120 cores
  # Coverage: 120 cores √∑ 58 avg = 2.1x average demand (good utilization target)
  #           120 cores √∑ 87 peak = 1.4x peak demand (allows some stress)
  initial_s_vm_count: 20    # Small (2 cores each) = 40 cores
  initial_m_vm_count: 10    # Medium (4 cores each) = 40 cores
  initial_l_vm_count: 5     # Large (8 cores each) = 40 cores

  # --- Simulation Settings ---
  simulation_timestep: 1.0
  min_time_between_events: 0.1
  max_episode_length: 7200  # üïê 1 hour episodes

  # --- RL Algorithm Configuration ---
  mode: "train"
  algorithm: "RecurrentPPO"
  policy: "MultiInputLstmPolicy"   # LSTM for temporal patterns

  # Training configuration
  timesteps: 1000000             # Long training (many 3600s episodes)
  learning_rate: 0.0003
  n_steps: 4096                 # Collect more steps before update
  batch_size: 256
  n_epochs: 10
  gamma: 0.995                  # High discount for long episodes
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.05                # Moderate exploration
  vf_coef: 0.5
  max_grad_norm: 0.5

  # --- LSTM Policy Configuration ---
  policy_kwargs:
    lstm_hidden_size: 256       # Large hidden state for 1-hour context
    n_lstm_layers: 1
    shared_lstm: true
    enable_critic_lstm: false
    net_arch:
      pi: [128, 128]            # Deeper actor head
      vf: [128, 128]            # Deeper critic head

  # --- Reward Weights ---
  # Balanced rewards for long episodes
  reward_wait_time_coef: 0.2
  reward_throughput_coef: 0.15
  reward_unutilization_coef: 0.03
  reward_cost_coef: 0.03 
  reward_queue_penalty_coef: 0.1
  reward_invalid_action_coef: 0.2

  # --- Other Settings ---
  seed: 3600
  save_experiment: true
  verbose: 1
  log_interval: 1
  device: "cuda"

  # --- VM Lifecycle ---
  vm_startup_delay: 0.0
  vm_shutdown_delay: 0.0


# ===================================================================
# HIERARCHICAL MULTI-DATACENTER EXPERIMENTS
# ===================================================================

# ===================================================================
# Experiment: Hierarchical Multi-DC - 3 Datacenters
# ===================================================================
# Two-level Hierarchical MARL:
# - Global Agent: Routes cloudlets to datacenters
# - Local Agents: Schedule cloudlets to VMs within each DC (parameter sharing)
#
# Features:
# - 3 heterogeneous datacenters with different wind turbines
# - Independent green energy sources per DC
# - Smart router (no global queue) - immediate routing upon arrival
# ===================================================================

experiment_multi_dc_3:
  # --- Identification ---
  simulation_name: "Hierarchical_3DC_Green"
  experiment_name: "hierarchical_3dc"
  experiment_type_dir: "Multi_Datacenter"

  # --- Multi-Datacenter Configuration ---
  multi_datacenter_enabled: true      # Enable multi-DC mode
  py4j_port: 25333                     # Py4J gateway port
  
  # Global Routing Configuration (Batch Mode - Recommended)
  global_routing_batch_size: 3         # Fixed batch size for global routing per timestep
                                       # - Agent routes up to 5 cloudlets per step
                                       # - Remaining cloudlets wait in global queue
                                       # - Provides stable action space for RL training
                                       # - Recommended: 3-10 based on workload arrival rate

  # --- Datacenter Configurations ---
  datacenters:
    # Datacenter 0: High-Performance DC
    - datacenter_id: 0
      name: "DC_HighPerformance"
      turbine_ids: [1]                 # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/Turbine_1_2021_clean.csv"  # 7.1 MB optimized file
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"  # COMPRESSED (1 data point = 1s) or REAL_TIME (1 data point = 600s)

      # Infrastructure
      hosts_count: 20
      host_pes: 24                     # More powerful hosts
      host_pe_mips: 60000              # Higher MIPS
      host_ram: 131072                 # 128 GB
      host_bw: 100000                  # 100 Gbps
      host_storage: 200000             # 200 GB

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # Initial VM Fleet (Optimized for 3-8 PE workloads)
      initial_s_vm_count: 8    # Reduced: Only for small jobs (1-2 PEs)
      initial_m_vm_count: 12   # Increased: For typical jobs (3-4 PEs)
      initial_l_vm_count: 10   # Increased: For large jobs (5-8 PEs)

      # VM Delays
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 1: Energy-Efficient DC
    - datacenter_id: 1
      name: "DC_EnergyEfficient"
      turbine_ids: [57]                # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/Turbine_57_2021_clean.csv"  # 7.1 MB optimized file
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"  # COMPRESSED (1 data point = 1s) or REAL_TIME (1 data point = 600s)

      # Infrastructure (lower power, more hosts)
      hosts_count: 24
      host_pes: 16
      host_pe_mips: 50000
      host_ram: 65536                  # 64 GB
      host_bw: 50000                   # 50 Gbps
      host_storage: 100000             # 100 GB

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # Initial VM Fleet (Optimized for 3-8 PE workloads)
      initial_s_vm_count: 6    # Reduced: Only for small jobs (1-2 PEs)
      initial_m_vm_count: 10   # Increased: For typical jobs (3-4 PEs)
      initial_l_vm_count: 8    # Increased: For large jobs (5-8 PEs)

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 2: Edge DC (Lower capacity)
    - datacenter_id: 2
      name: "DC_Edge"
      turbine_ids: [124]               # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/Turbine_124_2021_clean.csv"  # 7.2 MB optimized file
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"  # COMPRESSED (1 data point = 1s) or REAL_TIME (1 data point = 600s)

      # Infrastructure (smaller, edge location)
      hosts_count: 12
      host_pes: 12
      host_pe_mips: 40000              # Lower MIPS
      host_ram: 32768                  # 32 GB
      host_bw: 25000                   # 25 Gbps
      host_storage: 50000              # 50 GB

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 4096               # Smaller VMs
      small_vm_bw: 500
      small_vm_storage: 2000
      medium_vm_multiplier: 2
      large_vm_multiplier: 3           # Smaller large VMs

      # Initial VM Fleet (Edge DC - smaller capacity, optimized for 3-6 PE workloads)
      initial_s_vm_count: 4    # Reduced: Minimal small VMs
      initial_m_vm_count: 8    # Increased: Primary capacity
      initial_l_vm_count: 4    # Doubled: For larger jobs (note: Large VM here has 6 PEs)

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

  # --- Workload Configuration ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/multidc_light_workload.csv"
  max_cloudlets_to_create_from_workload_file: 2147483647
  workload_reader_mips: 50000
  split_large_cloudlets: true
  max_cloudlet_pes: 8

  # --- Simulation Settings ---
  simulation_timestep: 1.0
  min_time_between_events: 0.1
  max_episode_length: 2000

  # --- Global Agent Configuration ---
  global_agent:
    algorithm: "PPO"
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95

    # Global reward weights
    reward_total_energy_coef: 2.0     # Minimize total energy consumption
    reward_green_ratio_coef: 3.0      # Maximize green energy usage ratio
    reward_load_balance_coef: 1.5     # Balance load across DCs
    reward_global_queue_coef: 1.0     # Minimize total waiting cloudlets

  # --- Local Agents Configuration ---
  local_agents:
    algorithm: "MaskablePPO"
    parameter_sharing: true            # Share parameters across local agents
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95

    # Local reward weights
    reward_wait_time_coef: 1.0        # Minimize local wait time
    reward_utilization_coef: 0.8      # Maximize local utilization
    reward_local_queue_coef: 0.5      # Minimize local queue size
    reward_invalid_action_coef: 2.0   # Penalize invalid assignments

  # --- Training Configuration ---
  mode: "train"
  timesteps: 100000                    # Total timesteps for training
  seed: 2025
  save_experiment: true
  verbose: 1
  device: "auto"

  # --- Joint Training Configuration ---
  # Configuration for training Global and Local agents together
  joint_training:
    enabled: true                      # Enable joint training mode
    strategy: "alternating"            # Training strategy: "alternating" or "simultaneous"

    # Alternating training parameters (train global, then local, repeat)
    alternating:
      num_cycles: 10                   # Number of alternating training cycles
      global_steps_per_cycle: 10000    # Timesteps to train global agent per cycle
      local_steps_per_cycle: 10000     # Timesteps to train local agents per cycle

    # Simultaneous training parameters (experimental)
    simultaneous:
      batch_size: 1000                 # Mini-batch size for simultaneous updates
      global_weight: 0.5               # Weight for global agent updates [0, 1]
      local_weight: 0.5                # Weight for local agent updates [0, 1]

    # Checkpoint and logging
    checkpoint_freq: 10000             # Save checkpoint every N timesteps
    log_freq: 100                      # Log metrics every N timesteps
    tensorboard_log: true              # Enable TensorBoard logging

    # Early stopping for joint training
    early_stopping:
      enabled: false                   # Enable early stopping
      metric: "green_ratio"            # Metric to monitor: "green_ratio", "carbon", "reward"
      threshold: 0.80                  # Stop when metric reaches this value
      patience: 5                      # Cycles without improvement before stopping

  # --- RLlib Training Configuration ---
  # Configuration for PettingZoo + RLlib parallel training
  training:
    total_timesteps: 100000           # Total training timesteps
    num_workers: 0                    # 0 for single-process (avoid Windows DLL issues)
    num_gpus: 1                       # Number of GPUs (0=CPU only, 1=use GPU)
    train_batch_size: 4000            # Training batch size
    sgd_minibatch_size: 128           # SGD minibatch size
    num_sgd_iter: 10                  # Number of SGD iterations
    checkpoint_freq_timesteps: 10000  # Save checkpoint every N timesteps

  # --- Wind Prediction ---
  wind_prediction:
    enabled: false                    # Disable wind prediction for this experiment
    horizon: 8
    device: "cuda"

# ===================================================================
# EXPERIMENT: 5-Datacenter Hierarchical MARL for Green Scheduling
# ===================================================================
# Purpose: Large-scale multi-DC green scheduling with 5 diverse datacenters
# Features:
# - 5 datacenters with different characteristics (high-performance, energy-efficient, edge, mid-range, regional)
# - Parameter sharing for local agents
# - RLlib PPO training with PettingZoo
# - Wind energy integration for all DCs
# ===================================================================

experiment_multi_dc_5:
  # --- Identification ---
  simulation_name: "Hierarchical_5DC_Green"
  experiment_name: "hierarchical_5dc"
  experiment_type_dir: "Multi_Datacenter"

  # --- Multi-Datacenter Configuration ---
  multi_datacenter_enabled: true      # Enable multi-DC mode
  py4j_port: 25333                     # Py4J gateway port

  # Global Routing Configuration (Batch Mode - Recommended)
  global_routing_batch_size: 5         # Fixed batch size for global routing per timestep
                                       # - Agent routes up to 5 cloudlets per step
                                       # - Increased from 3 to handle more DCs
                                       # - Provides stable action space for RL training

  # --- Datacenter Configurations ---
  datacenters:
    # Datacenter 0: High-Performance DC
    - datacenter_id: 0
      name: "DC_HighPerformance"
      turbine_ids: [1]                 # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/simplified"  # Base directory, file inferred by turbineId
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"

      # Carbon Emission Factors (kg CO2 per kWh)
      brown_carbon_factor: 0.8         # Coal-heavy grid (high carbon intensity)
      green_carbon_factor: 0.01        # Wind lifecycle emissions

      # LOW_POWER:
      #   - Model: HP-DL360-G7-LowPower
      #   - Cores (PEs): 8
      #   - pe_mips: 50000
      #   - RAM: 32768 MB
      #   - BW: 10000 Mbps
      #   - Storage: 100000 MB
      #   - Max Power: 208 W
      #   - Static Power: 27.9 % (idle / peak)
      #
      # MEDIUM:
      #   - Model: Dell-R720-Medium
      #   - Cores (PEs): 16
      #   - pe_mips: 50000
      #   - RAM: 65536 MB
      #   - BW: 20000 Mbps
      #   - Storage: 200000 MB
      #   - Max Power: 345 W
      #   - Static Power: 28.4 %
      #
      # HIGH_PERFORMANCE:
      #   - Model: Cisco-UCS-C240-HighPerf
      #   - Cores (PEs): 24
      #   - pe_mips: 50000
      #   - RAM: 131072 MB
      #   - BW: 40000 Mbps
      #   - Storage: 500000 MB
      #   - Max Power: 476 W
      #   - Static Power: 29.8 %
      #
      # ULTRA_HIGH:
      #   - Model: HPE-DL380-Gen10-Ultra
      #   - Cores (PEs): 32
      #   - pe_mips: 50000
      #   - RAM: 262144 MB
      #   - BW: 50000 Mbps
      #   - Storage: 1000000 MB
      #   - Max Power: 634 W
      #   - Static Power: 30.6 %
      #
      # SPEC_ACER_R520 (Acer Altos R520 - Legacy):
      #   - CPU: Intel Xeon E5450
      #   - Cores (PEs): 8
      #   - pe_mips: 50000
      #   - RAM: 16384 MB
      #   - BW: 10000 Mbps
      #   - Storage: 100000 MB
      #   - Idle: 155 W, Peak: 269 W (57.6 % idle)
      #
      # SPEC_ACER_AR360 (Acer AR360 F2 - Medium Older):
      #   - CPU: Intel Xeon E5-2660
      #   - Cores (PEs): 16
      #   - pe_mips: 50000
      #   - RAM: 32768 MB
      #   - BW: 10000 Mbps
      #   - Storage: 200000 MB
      #   - Idle: 69.4 W, Peak: 315 W (22.0 % idle)
      #
      # SPEC_ASUS_RS720_E9 (ASUSTeK RS720-E9/RS8 - Modern Efficient):
      #   - CPU: Intel Xeon Platinum 8180 (2x28 cores)
      #   - Cores (PEs): 56
      #   - pe_mips: 50000
      #   - RAM: 131072 MB
      #   - BW: 25000 Mbps
      #   - Storage: 500000 MB
      #   - Idle: 48.2 W, Peak: 385 W (12.5 % idle)
      #
      # SPEC_ASUS_RS500A (ASUSTeK RS500A-E10-PS4 - Large AMD EPYC):
      #   - CPU: AMD EPYC 7742
      #   - Cores (PEs): 64
      #   - pe_mips: 50000
      #   - RAM: 262144 MB
      #   - BW: 25000 Mbps
      #   - Storage: 1000000 MB
      #   - Idle: 51.4 W, Peak: 214 W (24.0 % idle)
      #
      # SPEC_ASUS_RS700A (ASUSTeK RS700A-E9-RS4V2 - Ultra Dual-Socket):
      #   - CPU: AMD EPYC 7742 x2
      #   - Cores (PEs): 128
      #   - pe_mips: 50000
      #   - RAM: 524288 MB
      #   - BW: 40000 Mbps
      #   - Storage: 2000000 MB
      #   - Idle: 106 W, Peak: 430 W (24.7 % idle)


      # Infrastructure (Most powerful)
      
      # Heterogeneous host mix (total 20 hosts: 4√óRS700A + 8√óRS500A + 8√óRS720)
      host_count_spec_asus_rs700a: 4
      host_count_spec_asus_rs500a: 8
      host_count_spec_asus_rs720_e9: 8

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # Initial VM Fleet (‚âà40% of total host cores = 600+ cores)
      initial_s_vm_count: 40   # 40 √ó 2 = 80 cores
      initial_m_vm_count: 60   # 60 √ó 4 = 240 cores
      initial_l_vm_count: 35   # 35 √ó 8 = 280 cores

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 1: Energy-Efficient DC
    - datacenter_id: 1
      name: "DC_EnergyEfficient"
      turbine_ids: [57]                # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/simplified"  # Base directory, file inferred by turbineId
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"

      # Carbon Emission Factors (kg CO2 per kWh)
      brown_carbon_factor: 0.5         # Natural gas grid (medium carbon intensity)
      green_carbon_factor: 0.01        # Wind lifecycle emissions

      # Infrastructure (Lower power, more hosts)
      hosts_count: 24
      host_pes: 16
      host_pe_mips: 50000
      host_ram: 65536                  # 64 GB
      host_bw: 50000                   # 50 Gbps
      host_storage: 100000

      # Heterogeneous host mix emphasizing energy efficiency (total 20 hosts)
      host_count_spec_asus_rs500a: 10
      host_count_spec_asus_rs720_e9: 6
      host_count_low_power: 4

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # Initial VM Fleet (‚âà60% of host cores = 600+ cores)
      initial_s_vm_count: 30   # 30 √ó 2 = 60 cores
      initial_m_vm_count: 50   # 50 √ó 4 = 200 cores
      initial_l_vm_count: 40   # 40 √ó 8 = 320 cores

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 2: Edge DC (Lower capacity)
    - datacenter_id: 2
      name: "DC_Edge"
      turbine_ids: [124]               # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/simplified"  # Base directory, file inferred by turbineId
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"

      # Carbon Emission Factors (kg CO2 per kWh)
      brown_carbon_factor: 0.6         # Mixed grid (medium-high carbon intensity)
      green_carbon_factor: 0.01        # Wind lifecycle emissions

      # Infrastructure (Smaller, edge location)
      hosts_count: 12
      host_pes: 12
      host_pe_mips: 40000
      host_ram: 32768                  # 32 GB
      host_bw: 25000                   # 25 Gbps
      host_storage: 50000

      # Heterogeneous host mix for edge DC (legacy +‰ΩéÂäüËÄóËäÇÁÇπ)
      host_count_spec_acer_r520: 6
      host_count_spec_acer_ar360: 4
      host_count_low_power: 4

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 4096
      small_vm_bw: 500
      small_vm_storage: 2000
      medium_vm_multiplier: 2
      large_vm_multiplier: 3

      # Initial VM Fleet (kept lighter for edge constraints)
      initial_s_vm_count: 8    # 8 √ó 2 = 16 cores
      initial_m_vm_count: 12   # 12 √ó 4 = 48 cores
      initial_l_vm_count: 8    # 8 √ó 6 = 48 cores

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 3: Mid-Range DC (Balanced specs)
    - datacenter_id: 3
      name: "DC_MidRange"
      turbine_ids: [80]                # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/simplified"  # Base directory, file inferred by turbineId
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"

      # Carbon Emission Factors (kg CO2 per kWh)
      brown_carbon_factor: 0.3         # Clean grid (low carbon intensity - hydro/nuclear mix)
      green_carbon_factor: 0.01        # Wind lifecycle emissions

      # Infrastructure (Balanced performance and efficiency)
      hosts_count: 18
      host_pes: 20
      host_pe_mips: 55000
      host_ram: 98304                  # 96 GB
      host_bw: 75000                   # 75 Gbps
      host_storage: 150000

      # Heterogeneous host mix (balancedÊÄßËÉΩ+ËÉΩËÄó)
      host_count_spec_asus_rs720_e9: 5
      host_count_spec_asus_rs500a: 3
      host_count_medium: 6
      host_count_high_performance: 4

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # Initial VM Fleet (‚âà60% of host cores ‚âà 400 cores)
      initial_s_vm_count: 20   # 20 √ó 2 = 40 cores
      initial_m_vm_count: 35   # 35 √ó 4 = 140 cores
      initial_l_vm_count: 30   # 30 √ó 8 = 240 cores

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 4: Regional DC (Good capacity, different location)
    - datacenter_id: 4
      name: "DC_Regional"
      turbine_ids: [100]               # Wind turbine IDs (single turbine for now)
      wind_data_file: "windProduction/simplified"  # Base directory, file inferred by turbineId
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"

      # Carbon Emission Factors (kg CO2 per kWh)
      brown_carbon_factor: 0.45        # Natural gas grid (medium-low carbon intensity)
      green_carbon_factor: 0.01        # Wind lifecycle emissions

      # Infrastructure (Good all-around specs)
      hosts_count: 16
      host_pes: 18
      host_pe_mips: 52000
      host_ram: 65536                  # 64 GB
      host_bw: 60000                   # 60 Gbps
      host_storage: 120000

      # Heterogeneous host mix (regional DC with legacy + modern nodes)
      host_count_spec_acer_ar360: 6
      host_count_spec_acer_r520: 4
      host_count_spec_asus_rs500a: 4
      host_count_medium: 2

      # VM Configuration
      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # Initial VM Fleet (‚âà70% of host cores ‚âà 290 cores)
      initial_s_vm_count: 16   # 16 √ó 2 = 32 cores
      initial_m_vm_count: 25   # 25 √ó 4 = 100 cores
      initial_l_vm_count: 20   # 20 √ó 8 = 160 cores

      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

  # --- Workload Configuration ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/my_uniform.csv"
  max_cloudlets_to_create_from_workload_file: 2147483647
  workload_reader_mips: 50000
  split_large_cloudlets: true
  max_cloudlet_pes: 8

  # --- Simulation Settings ---
  simulation_timestep: 1.0
  min_time_between_events: 0.1
  max_episode_length: 2000

  # --- Carbon Emission Penalty Configuration ---
  # Coefficient for carbon emission penalty in global reward
  # Penalty = carbon_emission_penalty_coef √ó total_carbon_kg
  # 
  # Observed values from training (experiment_multi_dc_5):
  # - Local rewards magnitude: ~7,000 (negative, sum of 5 DCs)
  # - Carbon emission: ~0.31 kg CO2 per episode
  # - With coef=3000: penalty ~930, dominates reward ‚Üí completion rate drops!
  # - With coef=1000: penalty ~310, balanced ‚Üí carbon decreases, completion stable
  # 
  # Tuning guidelines:
  # - Start at 800-1200 for 5 DCs with ~0.3kg carbon
  # - Monitor completion_rate: if drops >5%, reduce coef
  # - Monitor carbon: if no decrease after 100 episodes, increase coef
  carbon_emission_penalty_coef: 1000.0

  # --- Completion Reward Configuration ---
  # Coefficient for completion reward in LOCAL agent reward (positive reward)
  # Formula: reward_completion = coef √ó completedThisStep
  #
  # Purpose: Prevent agents from sacrificing task completion for other objectives
  # 
  # Per-step magnitude analysis:
  # - Wait time penalty:    ~-0.3 per step
  # - Utilization penalty:  ~-0.4 per step
  # - Queue penalty:        ~-0.03 per step
  # - Total negative:       ~-0.73 per step
  #
  # Completion reward calculation (FIXED per-completion, no normalization):
  # - completedThisStep: 0 or 1 (occasionally 2-3)
  # - Each completion gives: coef √ó 1 = coef reward
  #
  # To achieve ~0.2 per completion (same magnitude as other penalties):
  #   coef = 0.2
  #
  # Recommended: 0.1-0.3 for balanced contribution
  reward_completion_coef: 0.2

  # --- Global Agent Configuration ---
  global_model:
    learning_rate: 0.0003
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
    n_epochs: 10

  # --- Local Agents Configuration ---
  local_model:
    learning_rate: 0.0003
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
    n_epochs: 10

  # --- RLlib Training Configuration ---
  training:
    total_timesteps: 320000           # Increased for 5 DCs
    num_workers: 0                    # 0 for single-process (avoid Windows DLL issues)
    num_gpus: 1                       # Number of GPUs (RTX 5080 16GB)
    train_batch_size: 4000            # Increased for 5 DCs
    sgd_minibatch_size: 512           # Â¢ûÂ§ßÂà∞512ÔºàRTX 5080ÂèØ‰ª•Â§ÑÁêÜÔºâ
    num_sgd_iter: 10
    checkpoint_freq_timesteps: 15000

  # --- Wind Prediction ---
  wind_prediction:
    enabled: false
    horizon: 8
    device: "cuda"

  # --- Other Settings ---
  mode: "train"
  seed: 2025
  save_experiment: true
  verbose: 1
  device: "auto"



# ===================================================================
# EXPERIMENT: 10-Datacenter Hierarchical MARL for Green Scheduling
# ===================================================================
# Purpose: Large-scale multi-DC green scheduling with 10 diverse datacenters
# Features:
# - 10 datacenters spanning different regions and capabilities
# - Diverse host configurations (SPEC-based real servers)
# - 10 different wind turbines for realistic energy diversity
# - Parameter sharing for local agents
# - RLlib PPO training with PettingZoo
# ===================================================================

experiment_multi_dc_10:
  # --- Identification ---
  simulation_name: "Hierarchical_10DC_Green"
  experiment_name: "hierarchical_10dc"
  experiment_type_dir: "Multi_Datacenter"

  # --- Multi-Datacenter Configuration ---
  multi_datacenter_enabled: true
  py4j_port: 25333                    # Same port as Java gateway

  # Global Routing Configuration
  global_routing_batch_size: 10       # Increased batch size for 10 DCs

  # --- Datacenter Configurations ---
  # ========================================================================
  # SINGLE HOST TYPE PER DC - Simplified for better resource management
  # Each DC uses ONE host profile to avoid fragmentation and ensure
  # predictable VM allocation. VM counts calculated to stay within:
  # - Core capacity (70% utilization target)
  # - Bandwidth capacity (95% utilization max)
  # - RAM capacity (80% utilization target)
  # ========================================================================
  datacenters:
    # ===============================
    # Tier 1: Premium DCs (RS700A - 128 cores, 512GB RAM, 40Gbps BW)
    # ===============================

    # Datacenter 0: Premium High-Performance (US West)
    # Host: SPEC_ASUS_RS700A - AMD EPYC 7742 x2 (128 cores, 512GB, 40Gbps)
    # 80 hosts √ó 128 cores = 10,240 total cores
    # VM allocation: 640 small + 320 medium + 160 large = 1120 VMs
    # Core usage: 640√ó2 + 320√ó4 + 160√ó8 = 3,840 cores (38%)
    # RAM/BW well under limits, no fragmentation risk
    - datacenter_id: 0
      name: "DC_Premium_West"
      turbine_ids: [1]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 0            # Baseline (PST) - 0 hours offset
      brown_carbon_factor: 0.7
      green_carbon_factor: 0.01

      # Single host type: RS700A (128 cores, 512GB RAM, 40Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs700a: 20

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 64/32/16)
      initial_s_vm_count: 128
      initial_m_vm_count: 64
      initial_l_vm_count: 32
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 1: Premium High-Performance (US East)
    # Host: SPEC_ASUS_RS700A - AMD EPYC 7742 x2 (128 cores, 512GB, 40Gbps)
    # 60 hosts √ó 128 cores = 7,680 total cores
    # VM allocation: 480 small + 240 medium + 120 large = 840 VMs
    # Core usage: 480√ó2 + 240√ó4 + 120√ó8 = 2,880 cores (38%)
    - datacenter_id: 1
      name: "DC_Premium_East"
      turbine_ids: [15]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 18           # +3 hours (EST) - 18 rows √ó 10min = 3 hours
      brown_carbon_factor: 0.65
      green_carbon_factor: 0.01

      # Single host type: RS700A (128 cores, 512GB RAM, 40Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs700a: 16

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 48/24/12)
      initial_s_vm_count: 96
      initial_m_vm_count: 48
      initial_l_vm_count: 24
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # ===============================
    # Tier 2: Green Energy-Efficient DCs (RS500A - 64 cores, 256GB RAM, 25Gbps BW)
    # ===============================

    # Datacenter 2: Energy-Efficient (Nordic)
    # Host: SPEC_ASUS_RS500A - AMD EPYC 7742 (64 cores, 256GB, 25Gbps)
    # 100 hosts √ó 64 cores = 6,400 total cores
    # VM allocation: 500 small + 250 medium + 125 large = 875 VMs
    # Core usage: 500√ó2 + 250√ó4 + 125√ó8 = 3,000 cores (47%)
    - datacenter_id: 2
      name: "DC_Green_Nordic"
      turbine_ids: [30]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 54           # +9 hours (CET) - 54 rows √ó 10min = 9 hours
      brown_carbon_factor: 0.25         # Very clean grid (hydro+nuclear)
      green_carbon_factor: 0.01

      # Single host type: RS500A (64 cores, 256GB RAM, 25Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs500a: 24

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 50/25/12)
      initial_s_vm_count: 100
      initial_m_vm_count: 50
      initial_l_vm_count: 24
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 3: Energy-Efficient (Germany) - SOLAR POWERED
    # Host: SPEC_ASUS_RS500A - AMD EPYC 7742 (64 cores, 256GB, 25Gbps)
    # 80 hosts √ó 64 cores = 5,120 total cores
    # VM allocation: 400 small + 200 medium + 100 large = 700 VMs
    # Core usage: 400√ó2 + 200√ó4 + 100√ó8 = 2,400 cores (47%)
    - datacenter_id: 3
      name: "DC_Green_Germany"
      turbine_ids: [1]                         # Not used when full path specified
      wind_data_file: "solarProduction/simplified/Solar_1_2020.csv"  # Solar Plant 1 (29.2 kW peak)
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 54           # +9 hours (CET) - 54 rows √ó 10min = 9 hours
      brown_carbon_factor: 0.4
      green_carbon_factor: 0.02                # Solar lifecycle emissions slightly higher

      # Single host type: RS500A (64 cores, 256GB RAM, 25Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs500a: 20

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 40/20/10)
      initial_s_vm_count: 80
      initial_m_vm_count: 40
      initial_l_vm_count: 20
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # ===============================
    # Tier 3: Regional DCs (RS720_E9 - 56 cores, 128GB RAM, 25Gbps BW)
    # ===============================

    # Datacenter 4: Regional (Central US)
    # Host: SPEC_ASUS_RS720_E9 - Intel Xeon Platinum 8180 (56 cores, 128GB, 25Gbps)
    # 50 hosts √ó 56 cores = 2,800 total cores, 6,400 GB RAM total
    # VM allocation: 160 small + 80 medium + 40 large = 280 VMs
    # Core usage: 160√ó2 + 80√ó4 + 40√ó8 = 960 cores (34%)
    # RAM usage: 160√ó8 + 80√ó16 + 40√ó32 = 3,840 GB (60%)
    - datacenter_id: 4
      name: "DC_Regional_Central"
      turbine_ids: [60]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 12           # +2 hours (CST) - 12 rows √ó 10min = 2 hours
      brown_carbon_factor: 0.55
      green_carbon_factor: 0.01

      # Single host type: RS720_E9 (56 cores, 128GB RAM, 25Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs720_e9: 10

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 16/8/4)
      initial_s_vm_count: 32
      initial_m_vm_count: 16
      initial_l_vm_count: 8
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 5: Regional (Southern US) - SOLAR POWERED
    # Host: SPEC_ASUS_RS720_E9 - Intel Xeon Platinum 8180 (56 cores, 128GB, 25Gbps)
    # 40 hosts √ó 56 cores = 2,240 total cores, 5,120 GB RAM total
    # VM allocation: 128 small + 64 medium + 32 large = 224 VMs
    # Core usage: 128√ó2 + 64√ó4 + 32√ó8 = 768 cores (34%)
    # RAM usage: 128√ó8 + 64√ó16 + 32√ó32 = 3,072 GB (60%)
    - datacenter_id: 5
      name: "DC_Regional_South"
      turbine_ids: [1]                         # Not used when full path specified
      wind_data_file: "solarProduction/simplified/Solar_2_2020.csv"  # Solar Plant 2 (26.0 kW peak)
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 12           # +2 hours (CST) - 12 rows √ó 10min = 2 hours
      brown_carbon_factor: 0.6
      green_carbon_factor: 0.02                # Solar lifecycle emissions slightly higher

      # Single host type: RS720_E9 (56 cores, 128GB RAM, 25Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs720_e9: 8

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 13/6/3)
      initial_s_vm_count: 26
      initial_m_vm_count: 12
      initial_l_vm_count: 6
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 6: Regional (Asia Pacific)
    # Host: SPEC_ASUS_RS500A - AMD EPYC 7742 (64 cores, 256GB, 25Gbps)
    # 60 hosts √ó 64 cores = 3,840 total cores
    # VM allocation: 300 small + 150 medium + 75 large = 525 VMs
    # Core usage: 300√ó2 + 150√ó4 + 75√ó8 = 1,800 cores (47%)
    - datacenter_id: 6
      name: "DC_Regional_APAC"
      turbine_ids: [90]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 96           # +16 hours (Asia) - 96 rows √ó 10min = 16 hours
      brown_carbon_factor: 0.75         # Coal-heavy grid
      green_carbon_factor: 0.01

      # Single host type: RS500A (64 cores, 256GB RAM, 25Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_asus_rs500a: 12

      small_vm_pes: 2
      small_vm_ram: 8192
      small_vm_bw: 1000
      small_vm_storage: 4000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up to increase utilization (was 30/15/8)
      initial_s_vm_count: 60
      initial_m_vm_count: 30
      initial_l_vm_count: 16
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # ===============================
    # Tier 4: Edge DCs (AR360 - 16 cores, 32GB RAM, 10Gbps BW)
    # ===============================

    # Datacenter 7: Edge (West Coast)
    # Host: SPEC_ACER_AR360 - Intel Xeon E5-2660 (16 cores, 32GB, 10Gbps)
    # 30 hosts √ó 16 cores = 480 total cores, 960 GB RAM
    # VM allocation: 48 small + 24 medium + 12 large = 84 VMs
    # Core usage: 48√ó2 + 24√ó4 + 12√ó8 = 288 cores (60%)
    # RAM usage: 48√ó4 + 24√ó8 + 12√ó16 = 576 GB (60%)
    - datacenter_id: 7
      name: "DC_Edge_West"
      turbine_ids: [105]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 0            # Baseline (PST) - 0 hours offset
      brown_carbon_factor: 0.5
      green_carbon_factor: 0.01

      # Single host type: AR360 (16 cores, 32GB RAM, 10Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_acer_ar360: 6

      # Smaller VMs for edge DC
      small_vm_pes: 2
      small_vm_ram: 4096
      small_vm_bw: 500
      small_vm_storage: 2000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up but keep edge DC relatively small (was 5/2/1)
      initial_s_vm_count: 10
      initial_m_vm_count: 4
      initial_l_vm_count: 2
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 8: Edge (East Coast)
    # Host: SPEC_ACER_AR360 - Intel Xeon E5-2660 (16 cores, 32GB, 10Gbps)
    # SCALED DOWN 10x: 3 hosts √ó 16 cores = 48 total cores
    # VM allocation: 5 small + 2 medium + 1 large = 8 VMs
    - datacenter_id: 8
      name: "DC_Edge_East"
      turbine_ids: [118]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 18           # +3 hours (EST) - 18 rows √ó 10min = 3 hours
      brown_carbon_factor: 0.55
      green_carbon_factor: 0.01

      # Single host type: AR360 (16 cores, 32GB RAM, 10Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_acer_ar360: 6

      # Smaller VMs for edge DC
      small_vm_pes: 2
      small_vm_ram: 4096
      small_vm_bw: 500
      small_vm_storage: 2000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up but keep edge DC relatively small (was 5/2/1)
      initial_s_vm_count: 10
      initial_m_vm_count: 4
      initial_l_vm_count: 2
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

    # Datacenter 9: Edge (Europe)
    # Host: SPEC_ACER_AR360 - Intel Xeon E5-2660 (16 cores, 32GB, 10Gbps)
    # SCALED DOWN 10x: 3 hosts √ó 16 cores = 48 total cores
    # VM allocation: 4 small + 2 medium + 1 large = 7 VMs
    - datacenter_id: 9
      name: "DC_Edge_Europe"
      turbine_ids: [130]
      wind_data_file: "windProduction/simplified"
      green_energy_enabled: true
      time_scaling_mode: "COMPRESSED"
      time_zone_offset_rows: 54           # +9 hours (CET) - 54 rows √ó 10min = 9 hours
      brown_carbon_factor: 0.45
      green_carbon_factor: 0.01

      # Single host type: AR360 (16 cores, 32GB RAM, 10Gbps BW per host)
      # SCALED DOWN 10x for faster simulation
      host_count_spec_acer_ar360: 6

      # Smaller VMs for edge DC
      small_vm_pes: 2
      small_vm_ram: 4096
      small_vm_bw: 500
      small_vm_storage: 2000
      medium_vm_multiplier: 2
      large_vm_multiplier: 4

      # VM counts moderately scaled up but keep edge DC relatively small (was 4/2/1)
      initial_s_vm_count: 8
      initial_m_vm_count: 4
      initial_l_vm_count: 2
      vm_startup_delay: 0.0
      vm_shutdown_delay: 0.0

  # --- Workload Configuration ---
  workload_mode: "CSV"
  cloudlet_trace_file: "traces/dc10_fast.csv"  # Faster cloudlets (~1.8s avg exec time)
  max_cloudlets_to_create_from_workload_file: 2147483647
  workload_reader_mips: 50000
  split_large_cloudlets: true
  max_cloudlet_pes: 8

  # --- Simulation Settings ---
  simulation_timestep: 1.0
  min_time_between_events: 0.1
  max_episode_length: 4000  # Reduced from 10000 (faster cloudlets complete sooner)

  # --- Reward Configuration ---
  carbon_emission_penalty_coef: 1500.0   # Increased for 10 DCs
  reward_completion_coef: 0.3            # Slightly higher completion reward

  # Local reward weights (used by Java)
  reward_wait_time_coef: 1.0
  reward_unutilization_coef: 1.0
  reward_queue_penalty_coef: 0.6
  reward_invalid_action_coef: 2.0

  # --- Global Agent Configuration ---
  global_model:
    learning_rate: 0.0003
    gamma: 0.99
    gae_lambda: 0.95

  # --- Local Model Configuration ---
  local_model:
    learning_rate: 0.0003
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5

  # --- Training Configuration (RLlib) ---
  training:
    total_timesteps: 500000 # More timesteps for 10 DCs
    num_workers: 0
    num_gpus: 1
    train_batch_size: 8000            # Larger batch for more agents
    sgd_minibatch_size: 256
    num_sgd_iter: 10
    checkpoint_freq_timesteps: 20000

  # --- Wind Prediction (disabled by default) ---
  wind_prediction:
    enabled: false
    horizon: 8
    device: "cuda"
