# ğŸ“ ä»£ç ä¿®æ”¹æ€»ç»“

## âœ… å·²å®Œæˆçš„ä¿®æ”¹

### **1. åˆ é™¤äº† training_progress.csv ç”Ÿæˆé€»è¾‘**

**åŸå› ï¼š**
- åœ¨ `local_mode=True` ä¸‹ï¼Œtraining_progress.csv çš„æ•°æ®ä¸å¯é ï¼ˆå…¨æ˜¯ 0ï¼‰
- monitor.csv å·²ç»åŒ…å«æ‰€æœ‰ episode-level çš„è¯¦ç»†æ•°æ®
- TensorBoard æä¾›å®æ—¶çš„èšåˆç»Ÿè®¡

**ä¿®æ”¹çš„æ–‡ä»¶ï¼š**
- `drl-manager/src/callbacks/rllib_green_energy_logger.py`

**åˆ é™¤çš„å†…å®¹ï¼š**
- `__init__` ä¸­åˆ›å»º training_progress.csv çš„ä»£ç 
- `_init_csv` ä¸­åˆå§‹åŒ– progress_file çš„ä»£ç 
- `on_train_result` ä¸­å†™å…¥ CSV çš„ä»£ç 

**ä¿ç•™çš„åŠŸèƒ½ï¼š**
- âœ… monitor.csvï¼ˆæ¯ä¸ª episode çš„è¯¦ç»†æ•°æ®ï¼‰
- âœ… best_episode_details.csvï¼ˆæœ€ä½³ episode è®°å½•ï¼‰
- âœ… TensorBoard æ—¥å¿—ï¼ˆLoss å’Œèšåˆç»Ÿè®¡ï¼‰

---

### **2. å¢å¼ºäº† TensorBoard æŒ‡æ ‡è®°å½•**

**æ–°å¢çš„ TensorBoard æŒ‡æ ‡ï¼š**

#### **Policy Loss å’Œ Value Lossï¼š**
- `global_agent/policy_loss` - Global Agent ç­–ç•¥æŸå¤±
- `global_agent/value_loss` - Global Agent ä»·å€¼æŸå¤±
- `global_agent/entropy` - Global Agent ç†µ

- `local_agents_avg/policy_loss` - Local Agents å¹³å‡ç­–ç•¥æŸå¤±
- `local_agents_avg/value_loss` - Local Agents å¹³å‡ä»·å€¼æŸå¤±
- `local_agents_avg/entropy` - Local Agents å¹³å‡ç†µ

- `local_agent_dc{id}/policy_loss` - å„ä¸ª DC çš„ç­–ç•¥æŸå¤±
- `local_agent_dc{id}/value_loss` - å„ä¸ª DC çš„ä»·å€¼æŸå¤±

#### **Agent Rewardsï¼š**
- `agent_rewards/global_agent` - Global Agent å¹³å‡ episode å¥–åŠ±
- `agent_rewards/local_agents_avg` - Local Agents å¹³å‡ episode å¥–åŠ±

**è¿™äº›æŒ‡æ ‡ä¼šè‡ªåŠ¨è®°å½•åˆ° TensorBoardï¼Œæ— éœ€é¢å¤–é…ç½®ï¼**

---

## ğŸ“Š æ•°æ®æŸ¥çœ‹æ–¹å¼å¯¹æ¯”

### **ä¹‹å‰ï¼ˆæœ‰é—®é¢˜ï¼‰ï¼š**
```
training_progress.csv â†’ å…¨æ˜¯ 0ï¼ˆä¸å¯ç”¨ï¼‰
monitor.csv â†’ æœ‰æ•°æ®
TensorBoard â†’ åªæœ‰ custom_metricsï¼ˆä¸æ˜“æ‰¾åˆ° Lossï¼‰
```

### **ç°åœ¨ï¼ˆå·²ä¼˜åŒ–ï¼‰ï¼š**
```
âŒ training_progress.csv â†’ å·²åˆ é™¤
âœ… monitor.csv â†’ æ¯ä¸ª episode çš„å®Œæ•´æ•°æ®
âœ… TensorBoard â†’ Policy/Value Loss + Agent Rewards + Energy Metrics
```

---

## ğŸš€ ä¸‹æ¬¡è®­ç»ƒå¦‚ä½•ä½¿ç”¨

### **1. å¯åŠ¨è®­ç»ƒï¼š**

```bash
cd drl-manager
python entrypoint_pettingzoo.py --experiment experiment_multi_dc_5 --total-timesteps 100000
```

### **2. å®æ—¶ç›‘æ§ï¼ˆTensorBoardï¼‰ï¼š**

æ‰“å¼€æ–°ç»ˆç«¯ï¼š
```bash
cd ..\logs\experiment_multi_dc_5
tensorboard --logdir=. --port=6006
```

æµè§ˆå™¨æ‰“å¼€ `http://localhost:6006`

**æœç´¢ä»¥ä¸‹å…³é”®è¯æŸ¥çœ‹æŒ‡æ ‡ï¼š**
- `global_agent/policy` â†’ Global Agent çš„ Policy Loss
- `global_agent/value` â†’ Global Agent çš„ Value Loss
- `local_agents_avg/policy` â†’ Local Agents å¹³å‡ Policy Loss
- `episode_reward_mean` â†’ Episode æ€»å¥–åŠ±
- `agent_rewards` â†’ å„ä¸ª Agent çš„å¥–åŠ±
- `carbon` â†’ ç¢³æ’æ”¾æŒ‡æ ‡

### **3. è®­ç»ƒå®Œæˆååˆ†æï¼ˆPython è„šæœ¬ï¼‰ï¼š**

```bash
cd drl-manager
python view_core_metrics.py <timestamp>
```

ä¼šç”Ÿæˆ episode-level çš„æ‰€æœ‰æŒ‡æ ‡å›¾è¡¨ã€‚

---

## ğŸ¯ æ ¸å¿ƒæŒ‡æ ‡ä½ç½®é€ŸæŸ¥

| ä½ è¦çœ‹çš„æŒ‡æ ‡ | åœ¨å“ªé‡ŒæŸ¥çœ‹ | æœç´¢å…³é”®è¯/æ–‡ä»¶ |
|------------|-----------|---------------|
| **Policy Loss** | TensorBoard | `global_agent/policy` æˆ– `local_agents_avg/policy` |
| **Value Loss** | TensorBoard | `global_agent/value` æˆ– `local_agents_avg/value` |
| **Episode Reward** | TensorBoard | `episode_reward_mean` |
| **Agent Rewards** | TensorBoard | `agent_rewards/global` æˆ– `agent_rewards/local` |
| **Carbon Emission (episode-level)** | monitor.csv | `total_carbon_kg` åˆ— |
| **Brown Energy (episode-level)** | monitor.csv | `brown_used_wh` åˆ— |
| **Green Ratio (episode-level)** | monitor.csv | `green_ratio` åˆ— |
| **Episode è¯¦ç»†æ•°æ®** | Python è„šæœ¬ | `python view_core_metrics.py <timestamp>` |

---

## ğŸ“ æ–‡ä»¶ç»“æ„å˜åŒ–

### **è®­ç»ƒåç”Ÿæˆçš„æ–‡ä»¶ï¼š**

```
logs/experiment_multi_dc_5/<timestamp>/
â”œâ”€â”€ monitor.csv                          â† âœ… æ¯ä¸ª episode çš„è¯¦ç»†æ•°æ®
â”œâ”€â”€ best_episode_details.csv             â† âœ… æœ€ä½³ episode è®°å½•
â”œâ”€â”€ episode_metrics.png                  â† âœ… å›¾è¡¨ï¼ˆè¿è¡Œ view_core_metrics.py åï¼‰
â””â”€â”€ multidc_training/
    â””â”€â”€ PPO_<id>/
        â”œâ”€â”€ events.out.tfevents.*        â† âœ… TensorBoard äº‹ä»¶æ–‡ä»¶
        â””â”€â”€ checkpoint_*/                â† âœ… æ¨¡å‹ checkpoint
```

**ä¸å†ç”Ÿæˆï¼š**
- âŒ `training_progress.csv`ï¼ˆå·²åˆ é™¤ï¼‰

---

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™æ ·æ›´å¥½

### **ä¼˜ç‚¹ï¼š**

1. âœ… **æ•°æ®æ›´å¯é ** - monitor.csv åœ¨ local_mode ä¸‹å®Œå…¨æ­£å¸¸
2. âœ… **TensorBoard æ›´æ¸…æ™°** - Policy/Value Loss æœ‰æ˜ç¡®çš„è·¯å¾„
3. âœ… **é¿å…æ··æ·†** - ä¸ä¼šæœ‰"ä¸ºä»€ä¹ˆ training_progress.csv å…¨æ˜¯ 0"çš„ç–‘é—®
4. âœ… **ä»£ç æ›´ç®€æ´** - åˆ é™¤äº†ä¸å·¥ä½œçš„ä»£ç 

### **æ²¡æœ‰æŸå¤±ï¼š**

- âŒ training_progress.csv æœ¬æ¥å°±ä¸å¯ç”¨ï¼ˆlocal_mode é™åˆ¶ï¼‰
- âœ… æ‰€æœ‰æœ‰ç”¨çš„æ•°æ®éƒ½åœ¨ monitor.csv å’Œ TensorBoard
- âœ… å¯ä»¥ç”¨ `view_core_metrics.py` ç”Ÿæˆæ›´å¥½çš„å¯è§†åŒ–

---

## ğŸ†˜ å¦‚æœé‡åˆ°é—®é¢˜

### **é—®é¢˜ 1: TensorBoard çœ‹ä¸åˆ° policy_lossï¼Ÿ**

**è§£å†³ï¼š**
1. ç¡®ä¿è®­ç»ƒè¿è¡Œäº†è‡³å°‘ 5-10 iterations
2. åˆ·æ–°æµè§ˆå™¨ï¼ˆCtrl+Rï¼‰
3. æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦æœ‰ `[Iteration X] Global Agent - Policy Loss: ...` è¾“å‡º

### **é—®é¢˜ 2: monitor.csv ä¸ºç©ºï¼Ÿ**

**è§£å†³ï¼š**
1. ç¡®ä¿è‡³å°‘å®Œæˆäº† 1 ä¸ª episodeï¼ˆæ¯ä¸ª episode é•¿åº¦ = episode_lengthï¼‰
2. æ£€æŸ¥è®­ç»ƒæ˜¯å¦æ­£å¸¸è¿è¡Œï¼ˆæ²¡æœ‰æŠ¥é”™ï¼‰

### **é—®é¢˜ 3: æƒ³æ¢å¤ training_progress.csvï¼Ÿ**

**ä¸æ¨è**ï¼Œå› ä¸ºå®ƒåœ¨ local_mode ä¸‹ä¸å·¥ä½œã€‚

å¦‚æœåšæŒï¼Œéœ€è¦ï¼š
1. å…³é—­ local_modeï¼ˆå¯èƒ½é‡åˆ° Windows DLL é—®é¢˜ï¼‰
2. æˆ–æ‰‹åŠ¨ä» monitor.csv ç”Ÿæˆæ±‡æ€»æ•°æ®

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

å·²åˆ›å»ºçš„æ–‡æ¡£ï¼š
- âœ… `TENSORBOARD_FINAL_GUIDE.md` - å®Œæ•´çš„ TensorBoard ä½¿ç”¨æŒ‡å—
- âœ… `VIEW_EPISODE_METRICS_README.md` - å¦‚ä½•æŸ¥çœ‹ episode-level æ•°æ®
- âœ… `TRAINING_PROGRESS_CSV_ISSUE.md` - training_progress.csv é—®é¢˜è¯¦è§£
- âœ… `view_core_metrics.py` - Python è„šæœ¬è‡ªåŠ¨å¯è§†åŒ–

---

## ğŸ“ æ€»ç»“

### **æ ¸å¿ƒæ”¹è¿›ï¼š**
1. åˆ é™¤äº†ä¸å·¥ä½œçš„ training_progress.csv
2. å¢å¼ºäº† TensorBoard çš„ Loss å’Œ Reward è®°å½•
3. æä¾›äº†æ›´å¥½çš„æ•°æ®æŸ¥çœ‹å·¥å…·ï¼ˆPython è„šæœ¬ï¼‰

### **ä¸‹æ¬¡è®­ç»ƒåªéœ€è¦ï¼š**
1. è¿è¡Œè®­ç»ƒ
2. ç”¨ TensorBoard ç›‘æ§ Loss å’Œ Reward
3. è®­ç»ƒå®Œæˆåç”¨ Python è„šæœ¬æŸ¥çœ‹è¯¦ç»†æ•°æ®

**å°±è¿™ä¹ˆç®€å•ï¼** ğŸ‰

