# ğŸ“Š TensorBoard å®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸ¯ å·²åˆ é™¤ training_progress.csv

`training_progress.csv` åœ¨ local_mode ä¸‹ä¸å¯é ï¼Œå·²ä»ä»£ç ä¸­åˆ é™¤ã€‚æ‰€æœ‰æ•°æ®é€šè¿‡ä»¥ä¸‹æ–¹å¼æŸ¥çœ‹ï¼š

1. **Episode-level æ•°æ®** â†’ `monitor.csv`ï¼ˆç”¨ Python è„šæœ¬å¯è§†åŒ–ï¼‰
2. **Loss æ›²çº¿å’Œèšåˆç»Ÿè®¡** â†’ **TensorBoard**

---

## ğŸš€ å¯åŠ¨ TensorBoard

```bash
cd D:\rl-cloudsimplus-greenscheduling\logs\experiment_multi_dc_5
tensorboard --logdir=. --port=6006
```

æµè§ˆå™¨æ‰“å¼€ï¼š`http://localhost:6006`

---

## ğŸ“ˆ TensorBoard ä¸­çš„æ ¸å¿ƒæŒ‡æ ‡

### **1ï¸âƒ£ Policy Loss å’Œ Value Loss**

#### **Global Agentï¼ˆå…¨å±€è·¯ç”±ç­–ç•¥ï¼‰**

æœç´¢ï¼š`global_agent`

ä½ ä¼šçœ‹åˆ°ï¼š
- **`global_agent/policy_loss`** - ç­–ç•¥ç½‘ç»œæŸå¤±
- **`global_agent/value_loss`** - ä»·å€¼ç½‘ç»œæŸå¤±
- **`global_agent/entropy`** - ç­–ç•¥ç†µï¼ˆæ¢ç´¢ç¨‹åº¦ï¼‰

#### **Local Agentsï¼ˆæœ¬åœ°è°ƒåº¦ç­–ç•¥ï¼‰**

æœç´¢ï¼š`local_agent`

ä½ ä¼šçœ‹åˆ°ï¼š
- **`local_agents_avg/policy_loss`** - æ‰€æœ‰æœ¬åœ° Agent å¹³å‡ç­–ç•¥æŸå¤±
- **`local_agents_avg/value_loss`** - æ‰€æœ‰æœ¬åœ° Agent å¹³å‡ä»·å€¼æŸå¤±
- **`local_agent_dc0/policy_loss`** - DC0 çš„ç­–ç•¥æŸå¤±
- **`local_agent_dc1/policy_loss`** - DC1 çš„ç­–ç•¥æŸå¤±
- ... ä»¥æ­¤ç±»æ¨

#### **âœ… å¥åº·çš„æŸå¤±æ›²çº¿ï¼š**

```
  â†‘
æŸ|â•²
å¤±|  â•²___
  |      â€¾â€¾â€¾â€¾
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Training Steps

âœ“ å‰æœŸå¿«é€Ÿä¸‹é™
âœ“ åæœŸå°å¹…æ³¢åŠ¨ï¼ˆæ­£å¸¸ï¼‰
```

---

### **2ï¸âƒ£ å„ä¸ª Agent çš„ Reward**

#### **Episode Rewardï¼ˆæ€»å¥–åŠ±ï¼‰**

æœç´¢ï¼š`episode_reward`

- **`episode_reward_mean`** - æ¯ä¸ª episode çš„å¹³å‡æ€»å¥–åŠ±
- **`episode_reward_max`** - æœ€å¤§ episode å¥–åŠ±
- **`episode_reward_min`** - æœ€å° episode å¥–åŠ±

#### **Agent-wise Rewardsï¼ˆAgent åˆ†è§£å¥–åŠ±ï¼‰**

æœç´¢ï¼š`agent_rewards`

- **`agent_rewards/global_agent`** - Global Agent çš„å¹³å‡ episode å¥–åŠ±
- **`agent_rewards/local_agents_avg`** - Local Agents çš„å¹³å‡ episode å¥–åŠ±

æˆ–è€…æœç´¢ï¼š`custom_metrics/.*agent_reward`

- **`custom_metrics/global_agent_reward_mean`** - Global Agent å¥–åŠ±
- **`custom_metrics/local_agents_avg_reward_mean`** - Local Agents å¹³å‡å¥–åŠ±

#### **âœ… æœŸæœ›è¶‹åŠ¿ï¼š**

```
  â†‘
å¥–|     â•±â€¾â€¾â€¾
åŠ±|   â•±
  | â•±
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Training Steps

âœ“ æŒç»­ä¸Šå‡
âœ“ æœ€ç»ˆè¶‹äºç¨³å®š
```

---

### **3ï¸âƒ£ Carbon Emission å’Œ Energy Metrics**

æœç´¢ï¼š`carbon` æˆ– `custom_metrics`

- **`custom_metrics/total_carbon_kg_mean`** - å¹³å‡ç¢³æ’æ”¾ï¼ˆkg CO2ï¼‰
- **`custom_metrics/brown_used_wh_mean`** - å¹³å‡æ£•è‰²èƒ½æºä½¿ç”¨ï¼ˆWhï¼‰
- **`custom_metrics/green_ratio_mean`** - ç»¿è‰²èƒ½æºä½¿ç”¨æ¯”ä¾‹
- **`custom_metrics/green_waste_wh_mean`** - ç»¿è‰²èƒ½æºæµªè´¹ï¼ˆWhï¼‰

#### **âœ… æœŸæœ›è¶‹åŠ¿ï¼š**

```
Carbon Emission åº”è¯¥ä¸‹é™ï¼š
  â†‘
ç¢³|â•²
æ’|  â•²_____
æ”¾|        â€¾â€¾â€¾
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Training Steps

Green Ratio åº”è¯¥ä¸Šå‡ï¼š
  â†‘
ç»¿|     â•±â€¾â€¾â€¾
è‰²|   â•±
æ¯”| â•±
ä¾‹â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Training Steps
```

---

## ğŸ” å¿«é€ŸæŸ¥æ‰¾æŒ‡æ ‡é€ŸæŸ¥è¡¨

| ä½ æƒ³çœ‹çš„æŒ‡æ ‡ | TensorBoard æœç´¢å…³é”®è¯ | å®Œæ•´è·¯å¾„ç¤ºä¾‹ |
|------------|---------------------|------------|
| **Global Policy Loss** | `global_agent/policy` | `global_agent/policy_loss` |
| **Global Value Loss** | `global_agent/value` | `global_agent/value_loss` |
| **Local Policy Loss (å¹³å‡)** | `local_agents_avg/policy` | `local_agents_avg/policy_loss` |
| **Local Value Loss (å¹³å‡)** | `local_agents_avg/value` | `local_agents_avg/value_loss` |
| **DC0 Policy Loss** | `local_agent_dc0` | `local_agent_dc0/policy_loss` |
| **Episode Reward** | `episode_reward_mean` | `episode_reward_mean` |
| **Global Agent Reward** | `agent_rewards/global` | `agent_rewards/global_agent` |
| **Local Agents Reward** | `agent_rewards/local` | `agent_rewards/local_agents_avg` |
| **Carbon Emission** | `carbon` | `custom_metrics/total_carbon_kg_mean` |
| **Green Energy Ratio** | `green_ratio` | `custom_metrics/green_ratio_mean` |

---

## ğŸ¨ TensorBoard ä½¿ç”¨æŠ€å·§

### **1. ä½¿ç”¨æœç´¢è¿‡æ»¤**

åœ¨å·¦ä¾§æœç´¢æ¡†è¾“å…¥å…³é”®è¯ï¼š

**åªçœ‹æŸå¤±ï¼š**
```
loss
```

**åªçœ‹å¥–åŠ±ï¼š**
```
reward
```

**åªçœ‹èƒ½æºæŒ‡æ ‡ï¼š**
```
carbon|green|brown
```

**åªçœ‹ Global Agentï¼š**
```
global_agent
```

**åªçœ‹ Local Agentsï¼š**
```
local_agent
```

### **2. è°ƒæ•´å¹³æ»‘åº¦**

å·¦ä¾§æœ‰ **Smoothing** æ»‘å—ï¼š
- é»˜è®¤ 0.6 é€šå¸¸å°±å¾ˆå¥½
- æ‹–åˆ° 0.8-0.9 å¯ä»¥çœ‹åˆ°æ›´å¹³æ»‘çš„è¶‹åŠ¿

### **3. éšè—ä¸éœ€è¦çš„æŒ‡æ ‡**

TensorBoard ä¼šæ˜¾ç¤ºå¾ˆå¤š Ray å†…éƒ¨æŒ‡æ ‡ï¼ˆ`ray/tune/counters/*` ç­‰ï¼‰

**éšè—æ–¹æ³•ï¼š**
1. æœç´¢ `counters`
2. ç‚¹å‡»æ¯ä¸ªå›¾è¡¨å³ä¸Šè§’çš„ âŒ éšè—
3. é‡å¤æ­¥éª¤éšè— `connector_metrics`ã€`done` ç­‰

**æœ€ååªä¿ç•™ï¼š**
- `global_agent/*`
- `local_agent*/*`
- `agent_rewards/*`
- `episode_reward_*`
- `custom_metrics/*`

### **4. å¯¹æ¯”å¤šä¸ªå®éªŒ**

å¦‚æœä½ è¿è¡Œäº†å¤šæ¬¡å®éªŒï¼š

```bash
tensorboard --logdir=logs/experiment_multi_dc_5
```

TensorBoard ä¼šè‡ªåŠ¨åŠ è½½æ‰€æœ‰æ—¶é—´æˆ³çš„å®éªŒï¼Œå¯ä»¥å¯¹æ¯”ä¸åŒè¶…å‚æ•°çš„æ•ˆæœã€‚

---

## ğŸ“Š å®Œæ•´çš„ç›‘æ§å·¥ä½œæµ

### **è®­ç»ƒæœŸé—´ï¼š**

**ç»ˆç«¯ 1 - è¿è¡Œè®­ç»ƒï¼š**
```bash
cd drl-manager
python entrypoint_pettingzoo.py --experiment experiment_multi_dc_5 --total-timesteps 100000
```

**ç»ˆç«¯ 2 - å¯åŠ¨ TensorBoardï¼š**
```bash
cd ..\logs\experiment_multi_dc_5
tensorboard --logdir=. --port=6006 --reload_interval=5
```

**æµè§ˆå™¨ï¼š**
æ‰“å¼€ `http://localhost:6006`

å®æ—¶æŸ¥çœ‹ï¼š
1. Policy Loss å’Œ Value Loss æ˜¯å¦ä¸‹é™ âœ…
2. Episode Reward æ˜¯å¦ä¸Šå‡ âœ…
3. Carbon Emission æ˜¯å¦ä¸‹é™ âœ…

---

### **è®­ç»ƒå®Œæˆåï¼š**

**æ–¹æ³• 1 - æŸ¥çœ‹ Episode-Level è¯¦ç»†æ•°æ®ï¼ˆæ¨èï¼‰ï¼š**

```bash
cd drl-manager
python view_core_metrics.py <timestamp>
```

ä¼šç”ŸæˆåŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„å›¾è¡¨ï¼Œä¿å­˜åˆ°ï¼š
```
logs/experiment_multi_dc_5/<timestamp>/episode_metrics.png
```

**æ–¹æ³• 2 - TensorBoard å›é¡¾ï¼š**

```bash
cd ..\logs\experiment_multi_dc_5
tensorboard --logdir=.
```

æŸ¥çœ‹å®Œæ•´çš„è®­ç»ƒæ›²çº¿ã€‚

**æ–¹æ³• 3 - ç›´æ¥è¯»å– CSVï¼š**

```python
import pandas as pd
df = pd.read_csv('logs/experiment_multi_dc_5/<timestamp>/monitor.csv')

# æŸ¥çœ‹æ‰€æœ‰åˆ—
print(df.columns)

# ç»˜åˆ¶ä»»æ„æŒ‡æ ‡
import matplotlib.pyplot as plt
plt.plot(df['episode'], df['brown_used_wh'])
plt.show()
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### **1. æ¨ªè½´æ˜¯ Training Stepsï¼Œä¸æ˜¯ Episode Number**

TensorBoard çš„æ¨ªè½´æ˜¯ï¼š
- **num_env_steps_sampled** - ç´¯è®¡ç¯å¢ƒé‡‡æ ·æ­¥æ•°

**ä¸æ˜¯** Episode Numberï¼ˆ1, 2, 3...ï¼‰

å¦‚æœä½ æƒ³çœ‹ **episode-level çš„æ•°æ®**ï¼ˆæ¨ªè½´ = Episode Numberï¼‰ï¼Œç”¨ï¼š
```bash
python view_core_metrics.py <timestamp>
```

### **2. Custom Metrics æ˜¯èšåˆç»Ÿè®¡**

`custom_metrics/total_carbon_kg_mean` æ˜¾ç¤ºçš„æ˜¯ï¼š
- è¯¥ iteration ä¸­æ‰€æœ‰ episode çš„**å¹³å‡å€¼**

**ä¸æ˜¯**å•ä¸ª episode çš„çœŸå®å€¼ã€‚

å•ä¸ª episode çš„çœŸå®å€¼åœ¨ `monitor.csv`ã€‚

### **3. åˆæœŸæ•°æ®å¯èƒ½ä¸ç¨³å®š**

è®­ç»ƒæœ€åˆå‡ ä¸ª iterationsï¼Œç»Ÿè®¡å¯èƒ½ä¸å‡†ç¡®ï¼ˆæ•°æ®ç‚¹å°‘ï¼‰ã€‚

ç­‰è®­ç»ƒè¿è¡Œ 10+ iterations åï¼Œæ›²çº¿ä¼šç¨³å®šä¸‹æ¥ã€‚

---

## ğŸ¯ æ£€æŸ¥åˆ—è¡¨

è®­ç»ƒè¿è¡Œåï¼Œåœ¨ TensorBoard ç¡®è®¤ä»¥ä¸‹æŒ‡æ ‡å¯è§ï¼š

### **æŸå¤±æ›²çº¿ï¼ˆå¿…é¡»æœ‰ï¼‰ï¼š**

- [ ] `global_agent/policy_loss` - å­˜åœ¨ä¸”ä¸‹é™
- [ ] `global_agent/value_loss` - å­˜åœ¨ä¸”ä¸‹é™
- [ ] `local_agents_avg/policy_loss` - å­˜åœ¨ä¸”ä¸‹é™
- [ ] `local_agents_avg/value_loss` - å­˜åœ¨ä¸”ä¸‹é™

### **å¥–åŠ±æŒ‡æ ‡ï¼ˆå¿…é¡»æœ‰ï¼‰ï¼š**

- [ ] `episode_reward_mean` - å­˜åœ¨ä¸”ä¸Šå‡
- [ ] `agent_rewards/global_agent` - å­˜åœ¨
- [ ] `agent_rewards/local_agents_avg` - å­˜åœ¨

### **èƒ½æºæŒ‡æ ‡ï¼ˆåº”è¯¥æœ‰ï¼‰ï¼š**

- [ ] `custom_metrics/total_carbon_kg_mean` - å­˜åœ¨ä¸”ä¸‹é™
- [ ] `custom_metrics/green_ratio_mean` - å­˜åœ¨ä¸”ä¸Šå‡
- [ ] `custom_metrics/brown_used_wh_mean` - å­˜åœ¨ä¸”ä¸‹é™

å¦‚æœä»¥ä¸ŠæŒ‡æ ‡å…¨éƒ¨ âœ“ï¼Œè¯´æ˜è®­ç»ƒæ­£å¸¸ä¸”æŒ‡æ ‡è®°å½•å®Œæ•´ï¼

---

## ğŸ†˜ å¸¸è§é—®é¢˜

### **Q: çœ‹ä¸åˆ° policy_loss å’Œ value_lossï¼Ÿ**

**A:** ç­‰å¾…è®­ç»ƒè‡³å°‘ 5-10 iterationsã€‚æœ€åˆå‡ ä¸ª iteration å¯èƒ½æ²¡æœ‰ learner_statsã€‚

æ£€æŸ¥è®­ç»ƒæ—¥å¿—ä¸­æ˜¯å¦æœ‰ï¼š
```
[Iteration X] Global Agent - Policy Loss: 0.xxxxx, Value Loss: 0.xxxxx
```

å¦‚æœæ—¥å¿—æœ‰è¾“å‡ºä½† TensorBoard æ²¡æ˜¾ç¤ºï¼Œåˆ·æ–°æµè§ˆå™¨ï¼ˆCtrl+Rï¼‰ã€‚

---

### **Q: custom_metrics é‡Œçš„å€¼å…¨æ˜¯ 0ï¼Ÿ**

**A:** è¿™æ˜¯ local_mode=True çš„é™åˆ¶ã€‚ä½† Policy Loss å’Œ Value Loss åº”è¯¥æ­£å¸¸æ˜¾ç¤ºï¼ˆä¸ä¾èµ– custom_metricsï¼‰ã€‚

carbon emission ç­‰æŒ‡æ ‡æŸ¥çœ‹ `monitor.csv`ã€‚

---

### **Q: æƒ³çœ‹æ¯ä¸ªæ•°æ®ä¸­å¿ƒçš„ç‹¬ç«‹æŒ‡æ ‡ï¼Ÿ**

**A:** æœç´¢ï¼š`local_agent_dc0` æˆ– `dc_0`

ä¼šçœ‹åˆ°ï¼š
- `local_agent_dc0/policy_loss`
- `local_agent_dc0/value_loss`
- `custom_metrics/dc_0/green_ratio_mean`

---

### **Q: è®­ç»ƒå¾ˆæ…¢ï¼ŒTensorBoard èƒ½åŠ é€Ÿå—ï¼Ÿ**

**A:** TensorBoard ä¸ä¼šå½±å“è®­ç»ƒé€Ÿåº¦ï¼ˆå®ƒåªæ˜¯è¯»å–æ—¥å¿—æ–‡ä»¶ï¼‰ã€‚

å¦‚æœè§‰å¾— TensorBoard åŠ è½½æ…¢ï¼Œå¯ä»¥ï¼š
1. åªåŠ è½½å•ä¸ªå®éªŒï¼š`tensorboard --logdir=logs/experiment_multi_dc_5/<timestamp>/multidc_training`
2. å‡å°‘ä¿ç•™çš„ checkpoint æ•°é‡ï¼ˆåœ¨ä»£ç ä¸­è®¾ç½® `num_to_keep=1`ï¼‰

---

## ğŸ’¾ æ•°æ®å¤‡ä»½å’Œå¯¼å‡º

### **ä» TensorBoard å¯¼å‡ºæ•°æ®ï¼š**

ç‚¹å‡»å›¾è¡¨å·¦ä¸‹è§’çš„ ğŸ“¥ æŒ‰é’®ï¼Œä¸‹è½½ CSV æ ¼å¼ã€‚

### **ç›´æ¥è¯»å– monitor.csvï¼š**

```python
import pandas as pd

# è¯»å–æ•°æ®
df = pd.read_csv('logs/experiment_multi_dc_5/<timestamp>/monitor.csv')

# å¯¼å‡ºä½ éœ€è¦çš„åˆ—
df[['episode', 'episode_reward', 'total_carbon_kg', 'brown_used_wh']].to_csv('my_results.csv', index=False)
```

---

## ğŸ“š æ€»ç»“

### **TensorBoard é€‚åˆçœ‹ï¼š**
âœ… Policy Loss å’Œ Value Loss
âœ… è®­ç»ƒè¿‡ç¨‹ä¸­çš„å®æ—¶è¶‹åŠ¿
âœ… å¤šä¸ªå®éªŒçš„å¯¹æ¯”

### **monitor.csv é€‚åˆçœ‹ï¼š**
âœ… æ¯ä¸ª episode çš„è¯¦ç»†æ•°æ®
âœ… Episode-level çš„ç²¾ç¡®åˆ†æ
âœ… ç”¨ Python/Excel è¿›è¡Œè‡ªå®šä¹‰åˆ†æ

### **æ¨èå·¥ä½œæµï¼š**
1. è®­ç»ƒæ—¶ç”¨ TensorBoard ç›‘æ§ Loss å’Œ Reward è¶‹åŠ¿
2. è®­ç»ƒå®Œæˆåç”¨ `view_core_metrics.py` åˆ†æ episode-level æ•°æ®
3. éœ€è¦æ›´æ·±å…¥åˆ†ææ—¶ç›´æ¥è¯»å– `monitor.csv`

---

**Happy Training! ğŸš€**

